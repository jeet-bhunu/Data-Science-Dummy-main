{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411f4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a806e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module statsmodels.tsa.arima.model in statsmodels.tsa.arima:\n",
      "\n",
      "NAME\n",
      "    statsmodels.tsa.arima.model - ARIMA model class.\n",
      "\n",
      "DESCRIPTION\n",
      "    Author: Chad Fulton\n",
      "    License: BSD-3\n",
      "\n",
      "CLASSES\n",
      "    statsmodels.tsa.statespace.sarimax.SARIMAX(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "        ARIMA\n",
      "    statsmodels.tsa.statespace.sarimax.SARIMAXResults(statsmodels.tsa.statespace.mlemodel.MLEResults)\n",
      "        ARIMAResults\n",
      "    statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper(statsmodels.tsa.statespace.mlemodel.MLEResultsWrapper)\n",
      "        ARIMAResultsWrapper\n",
      "    \n",
      "    class ARIMA(statsmodels.tsa.statespace.sarimax.SARIMAX)\n",
      "     |  ARIMA(endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, enforce_stationarity=True, enforce_invertibility=True, concentrate_scale=False, trend_offset=1, dates=None, freq=None, missing='none', validate_specification=True)\n",
      "     |  \n",
      "     |  Autoregressive Integrated Moving Average (ARIMA) model, and extensions\n",
      "     |  \n",
      "     |  This model is the basic interface for ARIMA-type models, including those\n",
      "     |  with exogenous regressors and those with seasonal components. The most\n",
      "     |  general form of the model is SARIMAX(p, d, q)x(P, D, Q, s). It also allows\n",
      "     |  all specialized cases, including\n",
      "     |  \n",
      "     |  - autoregressive models: AR(p)\n",
      "     |  - moving average models: MA(q)\n",
      "     |  - mixed autoregressive moving average models: ARMA(p, q)\n",
      "     |  - integration models: ARIMA(p, d, q)\n",
      "     |  - seasonal models: SARIMA(P, D, Q, s)\n",
      "     |  - regression with errors that follow one of the above ARIMA-type models\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like, optional\n",
      "     |      The observed time-series process :math:`y`.\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors.\n",
      "     |  order : tuple, optional\n",
      "     |      The (p,d,q) order of the model for the autoregressive, differences, and\n",
      "     |      moving average components. d is always an integer, while p and q may\n",
      "     |      either be integers or lists of integers.\n",
      "     |  seasonal_order : tuple, optional\n",
      "     |      The (P,D,Q,s) order of the seasonal component of the model for the\n",
      "     |      AR parameters, differences, MA parameters, and periodicity. Default\n",
      "     |      is (0, 0, 0, 0). D and s are always integers, while P and Q\n",
      "     |      may either be integers or lists of positive integers.\n",
      "     |  trend : str{'n','c','t','ct'} or iterable, optional\n",
      "     |      Parameter controlling the deterministic trend. Can be specified as a\n",
      "     |      string where 'c' indicates a constant term, 't' indicates a\n",
      "     |      linear trend in time, and 'ct' includes both. Can also be specified as\n",
      "     |      an iterable defining a polynomial, as in `numpy.poly1d`, where\n",
      "     |      `[1,1,0,1]` would denote :math:`a + bt + ct^3`. Default is 'c' for\n",
      "     |      models without integration, and no trend for models with integration.\n",
      "     |      Note that all trend terms are included in the model as exogenous\n",
      "     |      regressors, which differs from how trends are included in ``SARIMAX``\n",
      "     |      models.  See the Notes section for a precise definition of the\n",
      "     |      treatment of trend terms.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to require the autoregressive parameters to correspond\n",
      "     |      to a stationarity process.\n",
      "     |  enforce_invertibility : bool, optional\n",
      "     |      Whether or not to require the moving average parameters to correspond\n",
      "     |      to an invertible process.\n",
      "     |  concentrate_scale : bool, optional\n",
      "     |      Whether or not to concentrate the scale (variance of the error term)\n",
      "     |      out of the likelihood. This reduces the number of parameters by one.\n",
      "     |      This is only applicable when considering estimation by numerical\n",
      "     |      maximum likelihood.\n",
      "     |  trend_offset : int, optional\n",
      "     |      The offset at which to start time trend values. Default is 1, so that\n",
      "     |      if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\n",
      "     |      set when the model created by extending a previous dataset.\n",
      "     |  dates : array_like of datetime, optional\n",
      "     |      If no index is given by `endog` or `exog`, an array-like object of\n",
      "     |      datetime objects can be provided.\n",
      "     |  freq : str, optional\n",
      "     |      If no index is given by `endog` or `exog`, the frequency of the\n",
      "     |      time-series may be specified here as a Pandas offset or offset string.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This model incorporates both exogenous regressors and trend components\n",
      "     |  through \"regression with ARIMA errors\". This differs from the\n",
      "     |  specification estimated using ``SARIMAX`` which treats the trend\n",
      "     |  components separately from any included exogenous regressors. The full\n",
      "     |  specification of the model estimated here is:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      Y_{t}-\\delta_{0}-\\delta_{1}t-\\ldots-\\delta_{k}t^{k}-X_{t}\\beta\n",
      "     |          & =\\epsilon_{t} \\\\\n",
      "     |      \\left(1-L\\right)^{d}\\left(1-L^{s}\\right)^{D}\\Phi\\left(L\\right)\n",
      "     |      \\Phi_{s}\\left(L\\right)\\epsilon_{t}\n",
      "     |          & =\\Theta\\left(L\\right)\\Theta_{s}\\left(L\\right)\\eta_{t}\n",
      "     |  \n",
      "     |  where :math:`\\eta_t \\sim WN(0,\\sigma^2)` is a white noise process, L\n",
      "     |  is the lag operator, and :math:`G(L)` are lag polynomials corresponding\n",
      "     |  to the autoregressive (:math:`\\Phi`), seasonal autoregressive\n",
      "     |  (:math:`\\Phi_s`), moving average (:math:`\\Theta`), and seasonal moving\n",
      "     |  average components (:math:`\\Theta_s`).\n",
      "     |  \n",
      "     |  `enforce_stationarity` and `enforce_invertibility` are specified in the\n",
      "     |  constructor because they affect loglikelihood computations, and so should\n",
      "     |  not be changed on the fly. This is why they are not instead included as\n",
      "     |  arguments to the `fit` method.\n",
      "     |  \n",
      "     |  .. todo:: should concentrate_scale=True by default\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> mod = sm.tsa.arima.ARIMA(endog, order=(1, 0, 0))\n",
      "     |  >>> res = mod.fit()\n",
      "     |  >>> print(res.summary())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ARIMA\n",
      "     |      statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, enforce_stationarity=True, enforce_invertibility=True, concentrate_scale=False, trend_offset=1, dates=None, freq=None, missing='none', validate_specification=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, method=None, method_kwargs=None, gls=None, gls_kwargs=None, cov_type=None, cov_kwds=None, return_params=False, low_memory=False)\n",
      "     |      Fit (estimate) the parameters of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      method : str, optional\n",
      "     |          The method used for estimating the parameters of the model. Valid\n",
      "     |          options include 'statespace', 'innovations_mle', 'hannan_rissanen',\n",
      "     |          'burg', 'innovations', and 'yule_walker'. Not all options are\n",
      "     |          available for every specification (for example 'yule_walker' can\n",
      "     |          only be used with AR(p) models).\n",
      "     |      method_kwargs : dict, optional\n",
      "     |          Arguments to pass to the fit function for the parameter estimator\n",
      "     |          described by the `method` argument.\n",
      "     |      gls : bool, optional\n",
      "     |          Whether or not to use generalized least squares (GLS) to estimate\n",
      "     |          regression effects. The default is False if `method='statespace'`\n",
      "     |          and is True otherwise.\n",
      "     |      gls_kwargs : dict, optional\n",
      "     |          Arguments to pass to the GLS estimation fit method. Only applicable\n",
      "     |          if GLS estimation is used (see `gls` argument for details).\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'opg' unless memory conservation is used to avoid\n",
      "     |          computing the loglikelihood values for each observation, in which\n",
      "     |          case the default is 'oim'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Default is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ARIMAResults\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.arima.ARIMA(endog, order=(1, 0, 0))\n",
      "     |      >>> res = mod.fit()\n",
      "     |      >>> print(res.summary())\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize the SARIMAX model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      These initialization steps must occur following the parent class\n",
      "     |      __init__ function calls.\n",
      "     |  \n",
      "     |  initialize_default(self, approximate_diffuse_variance=None)\n",
      "     |      Initialize default\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Used primarily to enforce stationarity of the autoregressive lag\n",
      "     |      polynomial, invertibility of the moving average lag polynomial, and\n",
      "     |      positive variance parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Constrained parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the lag polynomial has non-consecutive powers (so that the\n",
      "     |      coefficient is zero on some element of the polynomial), then the\n",
      "     |      constraint function is not onto the entire space of invertible\n",
      "     |      polynomials, although it only excludes a very small portion very close\n",
      "     |      to the invertibility boundary.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer\n",
      "     |      \n",
      "     |      Used primarily to reverse enforcement of stationarity of the\n",
      "     |      autoregressive lag polynomial and invertibility of the moving average\n",
      "     |      lag polynomial.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Constrained parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the lag polynomial has non-consecutive powers (so that the\n",
      "     |      coefficient is zero on some element of the polynomial), then the\n",
      "     |      constraint function is not onto the entire space of invertible\n",
      "     |      polynomials, although it only excludes a very small portion very close\n",
      "     |      to the invertibility boundary.\n",
      "     |  \n",
      "     |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Updates the representation matrices to fill in the new parameter\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True..\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  initial_design\n",
      "     |      Initial design matrix\n",
      "     |  \n",
      "     |  initial_selection\n",
      "     |      Initial selection matrix\n",
      "     |  \n",
      "     |  initial_state_intercept\n",
      "     |      Initial state intercept vector\n",
      "     |  \n",
      "     |  initial_transition\n",
      "     |      Initial transition matrix\n",
      "     |  \n",
      "     |  model_latex_names\n",
      "     |      The latex names of all possible model parameters.\n",
      "     |  \n",
      "     |  model_names\n",
      "     |      The plain text names of all possible model parameters.\n",
      "     |  \n",
      "     |  model_orders\n",
      "     |      The orders of each of the polynomials in the model.\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      List of human readable parameter names (for parameters actually\n",
      "     |      included in the model).\n",
      "     |  \n",
      "     |  param_terms\n",
      "     |      List of parameters actually included in the model, in sorted order.\n",
      "     |      \n",
      "     |      TODO Make this an dict with slice or indices as the values.\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      Starting parameters for maximum likelihood estimation\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      "     |  \n",
      "     |  params_complete = ['trend', 'exog', 'ar', 'ma', 'seasonal_ar', 'season...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ARIMAResults(statsmodels.tsa.statespace.sarimax.SARIMAXResults)\n",
      "     |  ARIMAResults(model, params, filter_results, cov_type=None, **kwargs)\n",
      "     |  \n",
      "     |  Class to hold results from fitting an SARIMAX model.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  model : SARIMAX instance\n",
      "     |      The fitted model instance\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  specification : dictionary\n",
      "     |      Dictionary including all attributes from the SARIMAX model instance.\n",
      "     |  polynomial_ar : ndarray\n",
      "     |      Array containing autoregressive lag polynomial coefficients,\n",
      "     |      ordered from lowest degree to highest. Initialized with ones, unless\n",
      "     |      a coefficient is constrained to be zero (in which case it is zero).\n",
      "     |  polynomial_ma : ndarray\n",
      "     |      Array containing moving average lag polynomial coefficients,\n",
      "     |      ordered from lowest degree to highest. Initialized with ones, unless\n",
      "     |      a coefficient is constrained to be zero (in which case it is zero).\n",
      "     |  polynomial_seasonal_ar : ndarray\n",
      "     |      Array containing seasonal autoregressive lag polynomial coefficients,\n",
      "     |      ordered from lowest degree to highest. Initialized with ones, unless\n",
      "     |      a coefficient is constrained to be zero (in which case it is zero).\n",
      "     |  polynomial_seasonal_ma : ndarray\n",
      "     |      Array containing seasonal moving average lag polynomial coefficients,\n",
      "     |      ordered from lowest degree to highest. Initialized with ones, unless\n",
      "     |      a coefficient is constrained to be zero (in which case it is zero).\n",
      "     |  polynomial_trend : ndarray\n",
      "     |      Array containing trend polynomial coefficients, ordered from lowest\n",
      "     |      degree to highest. Initialized with ones, unless a coefficient is\n",
      "     |      constrained to be zero (in which case it is zero).\n",
      "     |  model_orders : list of int\n",
      "     |      The orders of each of the polynomials in the model.\n",
      "     |  param_terms : list of str\n",
      "     |      List of parameters actually included in the model, in sorted order.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.statespace.kalman_filter.FilterResults\n",
      "     |  statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ARIMAResults\n",
      "     |      statsmodels.tsa.statespace.sarimax.SARIMAXResults\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModelResults\n",
      "     |      statsmodels.base.model.LikelihoodModelResults\n",
      "     |      statsmodels.base.model.Results\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  append(self, endog, exog=None, refit=False, fit_kwargs=None, **kwargs)\n",
      "     |      Recreate the results object with new data appended to the original data\n",
      "     |      \n",
      "     |      Creates a new result object applied to a dataset that is created by\n",
      "     |      appending new data to the end of the model's original data. The new\n",
      "     |      results can then be used for analysis or forecasting.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          New observations from the modeled time-series process.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      refit : bool, optional\n",
      "     |          Whether to re-fit the parameters, based on the combined dataset.\n",
      "     |          Default is False (so parameters from the current results object\n",
      "     |          are used to create the new results object).\n",
      "     |      copy_initialization : bool, optional\n",
      "     |          Whether or not to copy the initialization from the current results\n",
      "     |          set to the new model. Default is False\n",
      "     |      fit_kwargs : dict, optional\n",
      "     |          Keyword arguments to pass to `fit` (if `refit=True`) or `filter` /\n",
      "     |          `smooth`.\n",
      "     |      copy_initialization : bool, optional\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to modify model specification\n",
      "     |          arguments when created the new model object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Updated Results object, that includes results from both the\n",
      "     |          original dataset and the new dataset.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `endog` and `exog` arguments to this method must be formatted in\n",
      "     |      the same way (e.g. Pandas Series versus Numpy array) as were the\n",
      "     |      `endog` and `exog` arrays passed to the original model.\n",
      "     |      \n",
      "     |      The `endog` argument to this method should consist of new observations\n",
      "     |      that occurred directly after the last element of `endog`. For any other\n",
      "     |      kind of dataset, see the `apply` method.\n",
      "     |      \n",
      "     |      This method will apply filtering to all of the original data as well\n",
      "     |      as to the new data. To apply filtering only to the new data (which\n",
      "     |      can be much faster if the original dataset is large), see the `extend`\n",
      "     |      method.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults.extend\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults.apply\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> index = pd.period_range(start='2000', periods=2, freq='A')\n",
      "     |      >>> original_observations = pd.Series([1.2, 1.5], index=index)\n",
      "     |      >>> mod = sm.tsa.SARIMAX(original_observations)\n",
      "     |      >>> res = mod.fit()\n",
      "     |      >>> print(res.params)\n",
      "     |      ar.L1     0.9756\n",
      "     |      sigma2    0.0889\n",
      "     |      dtype: float64\n",
      "     |      >>> print(res.fittedvalues)\n",
      "     |      2000    0.0000\n",
      "     |      2001    1.1707\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      >>> print(res.forecast(1))\n",
      "     |      2002    1.4634\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      \n",
      "     |      >>> new_index = pd.period_range(start='2002', periods=1, freq='A')\n",
      "     |      >>> new_observations = pd.Series([0.9], index=new_index)\n",
      "     |      >>> updated_res = res.append(new_observations)\n",
      "     |      >>> print(updated_res.params)\n",
      "     |      ar.L1     0.9756\n",
      "     |      sigma2    0.0889\n",
      "     |      dtype: float64\n",
      "     |      >>> print(updated_res.fittedvalues)\n",
      "     |      2000    0.0000\n",
      "     |      2001    1.1707\n",
      "     |      2002    1.4634\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      >>> print(updated_res.forecast(1))\n",
      "     |      2003    0.878\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.sarimax.SARIMAXResults:\n",
      "     |  \n",
      "     |  __init__(self, model, params, filter_results, cov_type=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  extend(self, endog, exog=None, **kwargs)\n",
      "     |      Recreate the results object for new data that extends the original data\n",
      "     |      \n",
      "     |      Creates a new result object applied to a new dataset that is assumed to\n",
      "     |      follow directly from the end of the model's original data. The new\n",
      "     |      results can then be used for analysis or forecasting.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          New observations from the modeled time-series process.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      fit_kwargs : dict, optional\n",
      "     |          Keyword arguments to pass to `filter` or `smooth`.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to modify model specification\n",
      "     |          arguments when created the new model object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Updated Results object, that includes results only for the new\n",
      "     |          dataset.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults.append\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults.apply\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `endog` argument to this method should consist of new observations\n",
      "     |      that occurred directly after the last element of the model's original\n",
      "     |      `endog` array. For any other kind of dataset, see the `apply` method.\n",
      "     |      \n",
      "     |      This method will apply filtering only to the new data provided by the\n",
      "     |      `endog` argument, which can be much faster than re-filtering the entire\n",
      "     |      dataset. However, the returned results object will only have results\n",
      "     |      for the new data. To retrieve results for both the new data and the\n",
      "     |      original data, see the `append` method.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> index = pd.period_range(start='2000', periods=2, freq='A')\n",
      "     |      >>> original_observations = pd.Series([1.2, 1.5], index=index)\n",
      "     |      >>> mod = sm.tsa.SARIMAX(original_observations)\n",
      "     |      >>> res = mod.fit()\n",
      "     |      >>> print(res.params)\n",
      "     |      ar.L1     0.9756\n",
      "     |      sigma2    0.0889\n",
      "     |      dtype: float64\n",
      "     |      >>> print(res.fittedvalues)\n",
      "     |      2000    0.0000\n",
      "     |      2001    1.1707\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      >>> print(res.forecast(1))\n",
      "     |      2002    1.4634\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      \n",
      "     |      >>> new_index = pd.period_range(start='2002', periods=1, freq='A')\n",
      "     |      >>> new_observations = pd.Series([0.9], index=new_index)\n",
      "     |      >>> updated_res = res.extend(new_observations)\n",
      "     |      >>> print(updated_res.params)\n",
      "     |      ar.L1     0.9756\n",
      "     |      sigma2    0.0889\n",
      "     |      dtype: float64\n",
      "     |      >>> print(updated_res.fittedvalues)\n",
      "     |      2002    1.4634\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      >>> print(updated_res.forecast(1))\n",
      "     |      2003    0.878\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |  \n",
      "     |  summary(self, alpha=0.05, start=None)\n",
      "     |      Summarize the Model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          Significance level for the confidence intervals. Default is 0.05.\n",
      "     |      start : int, optional\n",
      "     |          Integer of the start observation. Default is 0.\n",
      "     |      model_name : str\n",
      "     |          The name of the model used. Default is to use model class name.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      summary : Summary instance\n",
      "     |          This holds the summary table and text, which can be printed or\n",
      "     |          converted to various output formats.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.iolib.summary.Summary\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.sarimax.SARIMAXResults:\n",
      "     |  \n",
      "     |  arfreq\n",
      "     |      (array) Frequency of the roots of the reduced form autoregressive\n",
      "     |      lag polynomial\n",
      "     |  \n",
      "     |  arparams\n",
      "     |      (array) Autoregressive parameters actually estimated in the model.\n",
      "     |      Does not include seasonal autoregressive parameters (see\n",
      "     |      `seasonalarparams`) or parameters whose values are constrained to be\n",
      "     |      zero.\n",
      "     |  \n",
      "     |  arroots\n",
      "     |      (array) Roots of the reduced form autoregressive lag polynomial\n",
      "     |  \n",
      "     |  mafreq\n",
      "     |      (array) Frequency of the roots of the reduced form moving average\n",
      "     |      lag polynomial\n",
      "     |  \n",
      "     |  maparams\n",
      "     |      (array) Moving average parameters actually estimated in the model.\n",
      "     |      Does not include seasonal moving average parameters (see\n",
      "     |      `seasonalmaparams`) or parameters whose values are constrained to be\n",
      "     |      zero.\n",
      "     |  \n",
      "     |  maroots\n",
      "     |      (array) Roots of the reduced form moving average lag polynomial\n",
      "     |  \n",
      "     |  seasonalarparams\n",
      "     |      (array) Seasonal autoregressive parameters actually estimated in the\n",
      "     |      model. Does not include nonseasonal autoregressive parameters (see\n",
      "     |      `arparams`) or parameters whose values are constrained to be zero.\n",
      "     |  \n",
      "     |  seasonalmaparams\n",
      "     |      (array) Seasonal moving average parameters actually estimated in the\n",
      "     |      model. Does not include nonseasonal moving average parameters (see\n",
      "     |      `maparams`) or parameters whose values are constrained to be zero.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEResults:\n",
      "     |  \n",
      "     |  apply(self, endog, exog=None, refit=False, fit_kwargs=None, copy_initialization=False, **kwargs)\n",
      "     |      Apply the fitted parameters to new data unrelated to the original data\n",
      "     |      \n",
      "     |      Creates a new result object using the current fitted parameters,\n",
      "     |      applied to a completely new dataset that is assumed to be unrelated to\n",
      "     |      the model's original data. The new results can then be used for\n",
      "     |      analysis or forecasting.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          New observations from the modeled time-series process.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      refit : bool, optional\n",
      "     |          Whether to re-fit the parameters, using the new dataset.\n",
      "     |          Default is False (so parameters from the current results object\n",
      "     |          are used to create the new results object).\n",
      "     |      copy_initialization : bool, optional\n",
      "     |          Whether or not to copy the initialization from the current results\n",
      "     |          set to the new model. Default is False\n",
      "     |      fit_kwargs : dict, optional\n",
      "     |          Keyword arguments to pass to `fit` (if `refit=True`) or `filter` /\n",
      "     |          `smooth`.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to modify model specification\n",
      "     |          arguments when created the new model object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Updated Results object, that includes results only for the new\n",
      "     |          dataset.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults.append\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults.apply\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `endog` argument to this method should consist of new observations\n",
      "     |      that are not necessarily related to the original model's `endog`\n",
      "     |      dataset. For observations that continue that original dataset by follow\n",
      "     |      directly after its last element, see the `append` and `extend` methods.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> index = pd.period_range(start='2000', periods=2, freq='A')\n",
      "     |      >>> original_observations = pd.Series([1.2, 1.5], index=index)\n",
      "     |      >>> mod = sm.tsa.SARIMAX(original_observations)\n",
      "     |      >>> res = mod.fit()\n",
      "     |      >>> print(res.params)\n",
      "     |      ar.L1     0.9756\n",
      "     |      sigma2    0.0889\n",
      "     |      dtype: float64\n",
      "     |      >>> print(res.fittedvalues)\n",
      "     |      2000    0.0000\n",
      "     |      2001    1.1707\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      >>> print(res.forecast(1))\n",
      "     |      2002    1.4634\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      \n",
      "     |      >>> new_index = pd.period_range(start='1980', periods=3, freq='A')\n",
      "     |      >>> new_observations = pd.Series([1.4, 0.3, 1.2], index=new_index)\n",
      "     |      >>> new_res = res.apply(new_observations)\n",
      "     |      >>> print(new_res.params)\n",
      "     |      ar.L1     0.9756\n",
      "     |      sigma2    0.0889\n",
      "     |      dtype: float64\n",
      "     |      >>> print(new_res.fittedvalues)\n",
      "     |      1980    1.1707\n",
      "     |      1981    1.3659\n",
      "     |      1982    0.2927\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |      >>> print(new_res.forecast(1))\n",
      "     |      1983    1.1707\n",
      "     |      Freq: A-DEC, dtype: float64\n",
      "     |  \n",
      "     |  forecast(self, steps=1, **kwargs)\n",
      "     |      Out-of-sample forecasts\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      steps : int, str, or datetime, optional\n",
      "     |          If an integer, the number of steps to forecast from the end of the\n",
      "     |          sample. Can also be a date string to parse or a datetime type.\n",
      "     |          However, if the dates index does not have a fixed frequency, steps\n",
      "     |          must be an integer. Default\n",
      "     |      **kwargs\n",
      "     |          Additional arguments may required for forecasting beyond the end\n",
      "     |          of the sample. See `FilterResults.predict` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      forecast : array_like\n",
      "     |          Out-of-sample forecasts (Numpy array or Pandas Series or DataFrame,\n",
      "     |          depending on input and dimensions).\n",
      "     |          Dimensions are `(steps x k_endog)`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      predict\n",
      "     |          In-sample predictions and out-of-sample forecasts.\n",
      "     |      get_forecast\n",
      "     |          Out-of-sample forecasts and results including confidence intervals.\n",
      "     |      get_prediction\n",
      "     |          In-sample predictions / out-of-sample forecasts and results\n",
      "     |          including confidence intervals.\n",
      "     |  \n",
      "     |  get_forecast(self, steps=1, **kwargs)\n",
      "     |      Out-of-sample forecasts and prediction intervals\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      steps : int, str, or datetime, optional\n",
      "     |          If an integer, the number of steps to forecast from the end of the\n",
      "     |          sample. Can also be a date string to parse or a datetime type.\n",
      "     |          However, if the dates index does not have a fixed frequency, steps\n",
      "     |          must be an integer. Default\n",
      "     |      **kwargs\n",
      "     |          Additional arguments may required for forecasting beyond the end\n",
      "     |          of the sample. See `FilterResults.predict` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      forecasts : PredictionResults\n",
      "     |          PredictionResults instance containing out-of-sample forecasts and\n",
      "     |          results including confidence intervals.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      forecast\n",
      "     |          Out-of-sample forecasts.\n",
      "     |      predict\n",
      "     |          In-sample predictions and out-of-sample forecasts.\n",
      "     |      get_prediction\n",
      "     |          In-sample predictions / out-of-sample forecasts and results\n",
      "     |          including confidence intervals.\n",
      "     |  \n",
      "     |  get_prediction(self, start=None, end=None, dynamic=False, index=None, exog=None, extend_model=None, extend_kwargs=None, **kwargs)\n",
      "     |      In-sample prediction and out-of-sample forecasting\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the the zeroth observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out of sample prediction. Default is the last observation in\n",
      "     |          the sample.\n",
      "     |      dynamic : bool, int, str, or datetime, optional\n",
      "     |          Integer offset relative to `start` at which to begin dynamic\n",
      "     |          prediction. Can also be an absolute date string to parse or a\n",
      "     |          datetime type (these are not interpreted as offsets).\n",
      "     |          Prior to this observation, true endogenous values will be used for\n",
      "     |          prediction; starting with this observation and continuing through\n",
      "     |          the end of prediction, forecasted endogenous values will be used\n",
      "     |          instead.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments may required for forecasting beyond the end\n",
      "     |          of the sample. See `FilterResults.predict` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : PredictionResults\n",
      "     |          PredictionResults instance containing in-sample predictions /\n",
      "     |          out-of-sample forecasts and results including confidence intervals.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      forecast\n",
      "     |          Out-of-sample forecasts.\n",
      "     |      predict\n",
      "     |          In-sample predictions and out-of-sample forecasts.\n",
      "     |      get_forecast\n",
      "     |          Out-of-sample forecasts and results including confidence intervals.\n",
      "     |  \n",
      "     |  impulse_responses(self, steps=1, impulse=0, orthogonalized=False, cumulative=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |  \n",
      "     |  info_criteria(self, criteria, method='standard')\n",
      "     |      Information criteria\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      criteria : {'aic', 'bic', 'hqic'}\n",
      "     |          The information criteria to compute.\n",
      "     |      method : {'standard', 'lutkepohl'}\n",
      "     |          The method for information criteria computation. Default is\n",
      "     |          'standard' method; 'lutkepohl' computes the information criteria\n",
      "     |          as in Lütkepohl (2007). See Notes for formulas.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `'standard'` formulas are:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          AIC & = -2 \\log L(Y_n | \\hat \\psi) + 2 k \\\\\n",
      "     |          BIC & = -2 \\log L(Y_n | \\hat \\psi) + k \\log n \\\\\n",
      "     |          HQIC & = -2 \\log L(Y_n | \\hat \\psi) + 2 k \\log \\log n \\\\\n",
      "     |      \n",
      "     |      where :math:`\\hat \\psi` are the maximum likelihood estimates of the\n",
      "     |      parameters, :math:`n` is the number of observations, and `k` is the\n",
      "     |      number of estimated parameters.\n",
      "     |      \n",
      "     |      Note that the `'standard'` formulas are returned from the `aic`, `bic`,\n",
      "     |      and `hqic` results attributes.\n",
      "     |      \n",
      "     |      The `'lutkepohl'` formulas are (Lütkepohl, 2010):\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          AIC_L & = \\log | Q | + \\frac{2 k}{n} \\\\\n",
      "     |          BIC_L & = \\log | Q | + \\frac{k \\log n}{n} \\\\\n",
      "     |          HQIC_L & = \\log | Q | + \\frac{2 k \\log \\log n}{n} \\\\\n",
      "     |      \n",
      "     |      where :math:`Q` is the state covariance matrix. Note that the Lütkepohl\n",
      "     |      definitions do not apply to all state space models, and should be used\n",
      "     |      with care outside of SARIMAX and VARMAX models.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] Lütkepohl, Helmut. 2007. *New Introduction to Multiple Time*\n",
      "     |         *Series Analysis.* Berlin: Springer.\n",
      "     |  \n",
      "     |  news(self, comparison, impact_date=None, impacted_variable=None, start=None, end=None, periods=None, exog=None, comparison_type=None, return_raw=False, tolerance=1e-10, **kwargs)\n",
      "     |      Compute impacts from updated data (news and revisions)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      comparison : array_like or MLEResults\n",
      "     |          An updated dataset with updated and/or revised data from which the\n",
      "     |          news can be computed, or an updated or previous results object\n",
      "     |          to use in computing the news.\n",
      "     |      impact_date : int, str, or datetime, optional\n",
      "     |          A single specific period of impacts from news and revisions to\n",
      "     |          compute. Can also be a date string to parse or a datetime type.\n",
      "     |          This argument cannot be used in combination with `start`, `end`, or\n",
      "     |          `periods`. Default is the first out-of-sample observation.\n",
      "     |      impacted_variable : str, list, array, or slice, optional\n",
      "     |          Observation variable label or slice of labels specifying that only\n",
      "     |          specific impacted variables should be shown in the News output. The\n",
      "     |          impacted variable(s) describe the variables that were *affected* by\n",
      "     |          the news. If you do not know the labels for the variables, check\n",
      "     |          the `endog_names` attribute of the model instance.\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          The first period of impacts from news and revisions to compute.\n",
      "     |          Can also be a date string to parse or a datetime type. Default is\n",
      "     |          the first out-of-sample observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          The last period of impacts from news and revisions to compute.\n",
      "     |          Can also be a date string to parse or a datetime type. Default is\n",
      "     |          the first out-of-sample observation.\n",
      "     |      periods : int, optional\n",
      "     |          The number of periods of impacts from news and revisions to\n",
      "     |          compute.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors for the out-of-sample period, if\n",
      "     |          applicable.\n",
      "     |      comparison_type : {None, 'previous', 'updated'}\n",
      "     |          This denotes whether the `comparison` argument represents a\n",
      "     |          *previous* results object or dataset or an *updated* results object\n",
      "     |          or dataset. If not specified, then an attempt is made to determine\n",
      "     |          the comparison type.\n",
      "     |      return_raw : bool, optional\n",
      "     |          Whether or not to return only the specific output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      tolerance : float, optional\n",
      "     |          The numerical threshold for determining zero impact. Default is\n",
      "     |          that any impact less than 1e-10 is assumed to be zero.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      NewsResults\n",
      "     |          Impacts of data revisions and news on estimates\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Bańbura, Marta, and Michele Modugno.\n",
      "     |             \"Maximum likelihood estimation of factor models on datasets with\n",
      "     |             arbitrary pattern of missing data.\"\n",
      "     |             Journal of Applied Econometrics 29, no. 1 (2014): 133-160.\n",
      "     |      .. [2] Bańbura, Marta, Domenico Giannone, and Lucrezia Reichlin.\n",
      "     |             \"Nowcasting.\"\n",
      "     |             The Oxford Handbook of Economic Forecasting. July 8, 2011.\n",
      "     |      .. [3] Bańbura, Marta, Domenico Giannone, Michele Modugno, and Lucrezia\n",
      "     |             Reichlin.\n",
      "     |             \"Now-casting and the real-time data flow.\"\n",
      "     |             In Handbook of economic forecasting, vol. 2, pp. 195-237.\n",
      "     |             Elsevier, 2013.\n",
      "     |  \n",
      "     |  plot_diagnostics(self, variable=0, lags=10, fig=None, figsize=None, truncate_endog_names=24, auto_ylims=False, bartlett_confint=False, acf_kwargs=None)\n",
      "     |      Diagnostic plots for standardized residuals of one endogenous variable\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      variable : int, optional\n",
      "     |          Index of the endogenous variable for which the diagnostic plots\n",
      "     |          should be created. Default is 0.\n",
      "     |      lags : int, optional\n",
      "     |          Number of lags to include in the correlogram. Default is 10.\n",
      "     |      fig : Figure, optional\n",
      "     |          If given, subplots are created in this figure instead of in a new\n",
      "     |          figure. Note that the 2x2 grid will be created in the provided\n",
      "     |          figure using `fig.add_subplot()`.\n",
      "     |      figsize : tuple, optional\n",
      "     |          If a figure is created, this argument allows specifying a size.\n",
      "     |          The tuple is (width, height).\n",
      "     |      auto_ylims : bool, optional\n",
      "     |          If True, adjusts automatically the y-axis limits to ACF values.\n",
      "     |      bartlett_confint : bool, default True\n",
      "     |          Confidence intervals for ACF values are generally placed at 2\n",
      "     |          standard errors around r_k. The formula used for standard error\n",
      "     |          depends upon the situation. If the autocorrelations are being used\n",
      "     |          to test for randomness of residuals as part of the ARIMA routine,\n",
      "     |          the standard errors are determined assuming the residuals are white\n",
      "     |          noise. The approximate formula for any lag is that standard error\n",
      "     |          of each r_k = 1/sqrt(N). See section 9.4 of [1] for more details on\n",
      "     |          the 1/sqrt(N) result. For more elementary discussion, see section\n",
      "     |          5.3.2 in [2].\n",
      "     |          For the ACF of raw data, the standard error at a lag k is\n",
      "     |          found as if the right model was an MA(k-1). This allows the\n",
      "     |          possible interpretation that if all autocorrelations past a\n",
      "     |          certain lag are within the limits, the model might be an MA of\n",
      "     |          order defined by the last significant autocorrelation. In this\n",
      "     |          case, a moving average model is assumed for the data and the\n",
      "     |          standard errors for the confidence intervals should be\n",
      "     |          generated using Bartlett's formula. For more details on\n",
      "     |          Bartlett formula result, see section 7.2 in [1].+\n",
      "     |      acf_kwargs : dict, optional\n",
      "     |          Optional dictionary of keyword arguments that are directly passed\n",
      "     |          on to the correlogram Matplotlib plot produced by plot_acf().\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Figure\n",
      "     |          Figure instance with diagnostic plots\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.graphics.gofplots.qqplot\n",
      "     |      statsmodels.graphics.tsaplots.plot_acf\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Produces a 2x2 plot grid with the following plots (ordered clockwise\n",
      "     |      from top left):\n",
      "     |      \n",
      "     |      1. Standardized residuals over time\n",
      "     |      2. Histogram plus estimated density of standardized residuals, along\n",
      "     |         with a Normal(0,1) density plotted for reference.\n",
      "     |      3. Normal Q-Q plot, with Normal reference line.\n",
      "     |      4. Correlogram\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      [1] Brockwell and Davis, 1987. Time Series Theory and Methods\n",
      "     |      [2] Brockwell and Davis, 2010. Introduction to Time Series and\n",
      "     |      Forecasting, 2nd edition.\n",
      "     |  \n",
      "     |  predict(self, start=None, end=None, dynamic=False, **kwargs)\n",
      "     |      In-sample prediction and out-of-sample forecasting\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : {int, str,datetime}, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the zeroth observation.\n",
      "     |      end : {int, str,datetime}, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out of sample prediction. Default is the last observation in\n",
      "     |          the sample.\n",
      "     |      dynamic : {bool, int, str,datetime}, optional\n",
      "     |          Integer offset relative to `start` at which to begin dynamic\n",
      "     |          prediction. Can also be an absolute date string to parse or a\n",
      "     |          datetime type (these are not interpreted as offsets).\n",
      "     |          Prior to this observation, true endogenous values will be used for\n",
      "     |          prediction; starting with this observation and continuing through\n",
      "     |          the end of prediction, forecasted endogenous values will be used\n",
      "     |          instead.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments may be required for forecasting beyond the end\n",
      "     |          of the sample. See ``FilterResults.predict`` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : array_like\n",
      "     |          In-sample predictions / Out-of-sample forecasts. (Numpy array or\n",
      "     |          Pandas Series or DataFrame, depending on input and dimensions).\n",
      "     |          Dimensions are `(npredict x k_endog)`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      forecast\n",
      "     |          Out-of-sample forecasts.\n",
      "     |      get_forecast\n",
      "     |          Out-of-sample forecasts and results including confidence intervals.\n",
      "     |      get_prediction\n",
      "     |          In-sample predictions / out-of-sample forecasts and results\n",
      "     |          including confidence intervals.\n",
      "     |  \n",
      "     |  simulate(self, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Starting point from which to begin the simulations; type depends on\n",
      "     |          the index of the given `endog` model. Two special cases are the\n",
      "     |          strings 'start' and 'end', which refer to starting at the beginning\n",
      "     |          and end of the sample, respectively. If a date/time index was\n",
      "     |          provided to the model, then this argument can be a date string to\n",
      "     |          parse or a datetime type. Otherwise, an integer index should be\n",
      "     |          given. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  test_heteroskedasticity(self, method, alternative='two-sided', use_f=True)\n",
      "     |      Test for heteroskedasticity of standardized residuals\n",
      "     |      \n",
      "     |      Tests whether the sum-of-squares in the first third of the sample is\n",
      "     |      significantly different than the sum-of-squares in the last third\n",
      "     |      of the sample. Analogous to a Goldfeld-Quandt test. The null hypothesis\n",
      "     |      is of no heteroskedasticity.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'breakvar', None}\n",
      "     |          The statistical test for heteroskedasticity. Must be 'breakvar'\n",
      "     |          for test of a break in the variance. If None, an attempt is\n",
      "     |          made to select an appropriate test.\n",
      "     |      alternative : str, 'increasing', 'decreasing' or 'two-sided'\n",
      "     |          This specifies the alternative for the p-value calculation. Default\n",
      "     |          is two-sided.\n",
      "     |      use_f : bool, optional\n",
      "     |          Whether or not to compare against the asymptotic distribution\n",
      "     |          (chi-squared) or the approximate small-sample distribution (F).\n",
      "     |          Default is True (i.e. default is to compare against an F\n",
      "     |          distribution).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      output : ndarray\n",
      "     |          An array with `(test_statistic, pvalue)` for each endogenous\n",
      "     |          variable. The array is then sized `(k_endog, 2)`. If the method is\n",
      "     |          called as `het = res.test_heteroskedasticity()`, then `het[0]` is\n",
      "     |          an array of size 2 corresponding to the first endogenous variable,\n",
      "     |          where `het[0][0]` is the test statistic, and `het[0][1]` is the\n",
      "     |          p-value.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.stattools.breakvar_heteroskedasticity_test\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The null hypothesis is of no heteroskedasticity.\n",
      "     |      \n",
      "     |      For :math:`h = [T/3]`, the test statistic is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          H(h) = \\sum_{t=T-h+1}^T  \\tilde v_t^2\n",
      "     |          \\Bigg / \\sum_{t=d+1}^{d+1+h} \\tilde v_t^2\n",
      "     |      \n",
      "     |      where :math:`d` = max(loglikelihood_burn, nobs_diffuse)` (usually\n",
      "     |      corresponding to diffuse initialization under either the approximate\n",
      "     |      or exact approach).\n",
      "     |      \n",
      "     |      This statistic can be tested against an :math:`F(h,h)` distribution.\n",
      "     |      Alternatively, :math:`h H(h)` is asymptotically distributed according\n",
      "     |      to :math:`\\chi_h^2`; this second test can be applied by passing\n",
      "     |      `use_f=True` as an argument.\n",
      "     |      \n",
      "     |      See section 5.4 of [1]_ for the above formula and discussion, as well\n",
      "     |      as additional details.\n",
      "     |      \n",
      "     |      TODO\n",
      "     |      \n",
      "     |      - Allow specification of :math:`h`\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Harvey, Andrew C. 1990. *Forecasting, Structural Time Series*\n",
      "     |             *Models and the Kalman Filter.* Cambridge University Press.\n",
      "     |  \n",
      "     |  test_normality(self, method)\n",
      "     |      Test for normality of standardized residuals.\n",
      "     |      \n",
      "     |      Null hypothesis is normality.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'jarquebera', None}\n",
      "     |          The statistical test for normality. Must be 'jarquebera' for\n",
      "     |          Jarque-Bera normality test. If None, an attempt is made to select\n",
      "     |          an appropriate test.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.stats.stattools.jarque_bera\n",
      "     |          The Jarque-Bera test of normality.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Let `d` = max(loglikelihood_burn, nobs_diffuse); this test is\n",
      "     |      calculated ignoring the first `d` residuals.\n",
      "     |      \n",
      "     |      In the case of missing data, the maintained hypothesis is that the\n",
      "     |      data are missing completely at random. This test is then run on the\n",
      "     |      standardized residuals excluding those corresponding to missing\n",
      "     |      observations.\n",
      "     |  \n",
      "     |  test_serial_correlation(self, method, df_adjust=False, lags=None)\n",
      "     |      Ljung-Box test for no serial correlation of standardized residuals\n",
      "     |      \n",
      "     |      Null hypothesis is no serial correlation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'ljungbox','boxpierece', None}\n",
      "     |          The statistical test for serial correlation. If None, an attempt is\n",
      "     |          made to select an appropriate test.\n",
      "     |      lags : None, int or array_like\n",
      "     |          If lags is an integer then this is taken to be the largest lag\n",
      "     |          that is included, the test result is reported for all smaller lag\n",
      "     |          length.\n",
      "     |          If lags is a list or array, then all lags are included up to the\n",
      "     |          largest lag in the list, however only the tests for the lags in the\n",
      "     |          list are reported.\n",
      "     |          If lags is None, then the default maxlag is 12*(nobs/100)^{1/4}.\n",
      "     |          After 0.12 the default maxlag will change to min(10, nobs // 5) for\n",
      "     |          non-seasonal models and min(2*m, nobs // 5) for seasonal time\n",
      "     |          series where m is the seasonal period.\n",
      "     |      df_adjust : bool, optional\n",
      "     |          If True, the degrees of freedom consumed by the model is subtracted\n",
      "     |          from the degrees-of-freedom used in the test so that the adjusted\n",
      "     |          dof for the statistics are lags - model_df. In an ARMA model, this\n",
      "     |          value is usually p+q where p is the AR order and q is the MA order.\n",
      "     |          When using df_adjust, it is not possible to use tests based on\n",
      "     |          fewer than model_df lags.\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      output : ndarray\n",
      "     |          An array with `(test_statistic, pvalue)` for each endogenous\n",
      "     |          variable and each lag. The array is then sized\n",
      "     |          `(k_endog, 2, lags)`. If the method is called as\n",
      "     |          `ljungbox = res.test_serial_correlation()`, then `ljungbox[i]`\n",
      "     |          holds the results of the Ljung-Box test (as would be returned by\n",
      "     |          `statsmodels.stats.diagnostic.acorr_ljungbox`) for the `i` th\n",
      "     |          endogenous variable.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.stats.diagnostic.acorr_ljungbox\n",
      "     |          Ljung-Box test for serial correlation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Let `d` = max(loglikelihood_burn, nobs_diffuse); this test is\n",
      "     |      calculated ignoring the first `d` residuals.\n",
      "     |      \n",
      "     |      Output is nan for any endogenous variable which has missing values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.statespace.mlemodel.MLEResults:\n",
      "     |  \n",
      "     |  states\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEResults:\n",
      "     |  \n",
      "     |  aic\n",
      "     |      (float) Akaike Information Criterion\n",
      "     |  \n",
      "     |  aicc\n",
      "     |      (float) Akaike Information Criterion with small sample correction\n",
      "     |  \n",
      "     |  bic\n",
      "     |      (float) Bayes Information Criterion\n",
      "     |  \n",
      "     |  cov_params_approx\n",
      "     |      (array) The variance / covariance matrix. Computed using the numerical\n",
      "     |      Hessian approximated by complex step or finite differences methods.\n",
      "     |  \n",
      "     |  cov_params_oim\n",
      "     |      (array) The variance / covariance matrix. Computed using the method\n",
      "     |      from Harvey (1989).\n",
      "     |  \n",
      "     |  cov_params_opg\n",
      "     |      (array) The variance / covariance matrix. Computed using the outer\n",
      "     |      product of gradients method.\n",
      "     |  \n",
      "     |  cov_params_robust\n",
      "     |      (array) The QMLE variance / covariance matrix. Alias for\n",
      "     |      `cov_params_robust_oim`\n",
      "     |  \n",
      "     |  cov_params_robust_approx\n",
      "     |      (array) The QMLE variance / covariance matrix. Computed using the\n",
      "     |      numerical Hessian as the evaluated hessian.\n",
      "     |  \n",
      "     |  cov_params_robust_oim\n",
      "     |      (array) The QMLE variance / covariance matrix. Computed using the\n",
      "     |      method from Harvey (1989) as the evaluated hessian.\n",
      "     |  \n",
      "     |  fittedvalues\n",
      "     |      (array) The predicted values of the model. An (nobs x k_endog) array.\n",
      "     |  \n",
      "     |  hqic\n",
      "     |      (float) Hannan-Quinn Information Criterion\n",
      "     |  \n",
      "     |  llf\n",
      "     |      (float) The value of the log-likelihood function evaluated at `params`.\n",
      "     |  \n",
      "     |  llf_obs\n",
      "     |      (float) The value of the log-likelihood function evaluated at `params`.\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |      (float) The number of observations during which the likelihood is not\n",
      "     |      evaluated.\n",
      "     |  \n",
      "     |  mae\n",
      "     |      (float) Mean absolute error\n",
      "     |  \n",
      "     |  mse\n",
      "     |      (float) Mean squared error\n",
      "     |  \n",
      "     |  pvalues\n",
      "     |      (array) The p-values associated with the z-statistics of the\n",
      "     |      coefficients. Note that the coefficients are assumed to have a Normal\n",
      "     |      distribution.\n",
      "     |  \n",
      "     |  resid\n",
      "     |      (array) The model residuals. An (nobs x k_endog) array.\n",
      "     |  \n",
      "     |  sse\n",
      "     |      (float) Sum of squared errors\n",
      "     |  \n",
      "     |  zvalues\n",
      "     |      (array) The z-statistics for the coefficients.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None)\n",
      "     |      Construct confidence interval for the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval. The default\n",
      "     |          `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array_like, optional\n",
      "     |          Specifies which confidence intervals to return.\n",
      "     |      \n",
      "     |      .. deprecated: 0.13\n",
      "     |      \n",
      "     |         cols is deprecated and will be removed after 0.14 is released.\n",
      "     |         cols only works when inputs are NumPy arrays and will fail\n",
      "     |         when using pandas Series or DataFrames as input. You can\n",
      "     |         subset the confidence intervals using slices.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution\n",
      "     |      if self.use_t is False. If self.use_t is True, then uses a Student's t\n",
      "     |      with self.df_resid_inference (or self.df_resid if df_resid_inference is\n",
      "     |      not defined) degrees of freedom.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      Compute the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast of the\n",
      "     |      estimated parameters or all params multiplied by scale which will\n",
      "     |      usually be an estimate of sigma^2.  Scale is assumed to be a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array_like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column : array_like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      cov_p : ndarray, optional\n",
      "     |          The covariance of the parameters. If not provided, this value is\n",
      "     |          read from `self.normalized_cov_params` or\n",
      "     |          `self.cov_params_default`.\n",
      "     |      other : array_like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  f_test(self, r_matrix, cov_p=None, invcov=None)\n",
      "     |      Compute the F-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      This is a special case of `wald_test` that always uses the F\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : {array_like, str, tuple}\n",
      "     |          One of:\n",
      "     |      \n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length k row vector.\n",
      "     |      \n",
      "     |      cov_p : array_like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      invcov : array_like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ContrastResults\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      t_test : Perform a single hypothesis test.\n",
      "     |      wald_test : Perform a Wald-test using a quadratic form.\n",
      "     |      statsmodels.stats.contrast.ContrastResults : Test results.\n",
      "     |      patsy.DesignInfo.linear_constraint : Specify a linear constraint.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> A = np.identity(len(results.params))\n",
      "     |      >>> A = A[1:,:]\n",
      "     |      \n",
      "     |      This tests that each coefficient is jointly statistically\n",
      "     |      significantly different from zero.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(A))\n",
      "     |      <F test: F=array([[ 330.28533923]]), p=4.984030528700946e-10, df_denom=9, df_num=6>\n",
      "     |      \n",
      "     |      Compare this to\n",
      "     |      \n",
      "     |      >>> results.fvalue\n",
      "     |      330.2853392346658\n",
      "     |      >>> results.f_pvalue\n",
      "     |      4.98403096572e-10\n",
      "     |      \n",
      "     |      >>> B = np.array(([0,0,1,-1,0,0,0],[0,0,0,0,0,1,-1]))\n",
      "     |      \n",
      "     |      This tests that the coefficient on the 2nd and 3rd regressors are\n",
      "     |      equal and jointly that the coefficient on the 5th and 6th regressors\n",
      "     |      are equal.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(B))\n",
      "     |      <F test: F=array([[ 9.74046187]]), p=0.005605288531708235, df_denom=9, df_num=2>\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.datasets import longley\n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n",
      "     |      >>> f_test = results.f_test(hypotheses)\n",
      "     |      >>> print(f_test)\n",
      "     |      <F test: F=array([[ 144.17976065]]), p=6.322026217355609e-08, df_denom=9, df_num=3>\n",
      "     |  \n",
      "     |  normalized_cov_params(self)\n",
      "     |      See specific model class docstring\n",
      "     |  \n",
      "     |  remove_data(self)\n",
      "     |      Remove data arrays, all nobs arrays from result and model.\n",
      "     |      \n",
      "     |      This reduces the size of the instance, so it can be pickled with less\n",
      "     |      memory. Currently tested for use with predict from an unpickled\n",
      "     |      results and model instance.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |         Since data and some intermediate results have been removed\n",
      "     |         calculating new statistics that require them will raise exceptions.\n",
      "     |         The exception will occur the first time an attribute is accessed\n",
      "     |         that has been set to None.\n",
      "     |      \n",
      "     |      Not fully tested for time series models, tsa, and might delete too much\n",
      "     |      for prediction or not all that would be possible.\n",
      "     |      \n",
      "     |      The lists of arrays to delete are maintained as attributes of\n",
      "     |      the result and model instance, except for cached values. These\n",
      "     |      lists could be changed before calling remove_data.\n",
      "     |      \n",
      "     |      The attributes to remove are named in:\n",
      "     |      \n",
      "     |      model._data_attr : arrays attached to both the model instance\n",
      "     |          and the results instance with the same attribute name.\n",
      "     |      \n",
      "     |      result._data_in_cache : arrays that may exist as values in\n",
      "     |          result._cache\n",
      "     |      \n",
      "     |      result._data_attr_model : arrays attached to the model\n",
      "     |          instance but not to the results instance\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      Save a pickle of this instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle}\n",
      "     |          A string filename or a file handle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If remove_data is true and the model result does not implement a\n",
      "     |      remove_data method then this will raise an exception.\n",
      "     |  \n",
      "     |  t_test(self, r_matrix, cov_p=None, use_t=None)\n",
      "     |      Compute a t-test for a each linear hypothesis of the form Rb = q.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : {array_like, str, tuple}\n",
      "     |          One of:\n",
      "     |      \n",
      "     |          - array : If an array is given, a p x k 2d array or length k 1d\n",
      "     |            array specifying the linear restrictions. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q). If q is given,\n",
      "     |            can be either a scalar or a length p row vector.\n",
      "     |      \n",
      "     |      cov_p : array_like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      use_t : bool, optional\n",
      "     |          If use_t is None, then the default of the model is used. If use_t\n",
      "     |          is True, then the p-values are based on the t distribution. If\n",
      "     |          use_t is False, then the p-values are based on the normal\n",
      "     |          distribution.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ContrastResults\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |          The available results have the same elements as the parameter table\n",
      "     |          in `summary()`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      tvalues : Individual t statistics for the estimated parameters.\n",
      "     |      f_test : Perform an F tests on model parameters.\n",
      "     |      patsy.DesignInfo.linear_constraint : Specify a linear constraint.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> r = np.zeros_like(results.params)\n",
      "     |      >>> r[5:] = [1,-1]\n",
      "     |      >>> print(r)\n",
      "     |      [ 0.  0.  0.  0.  0.  1. -1.]\n",
      "     |      \n",
      "     |      r tests that the coefficients on the 5th and 6th independent\n",
      "     |      variable are the same.\n",
      "     |      \n",
      "     |      >>> T_test = results.t_test(r)\n",
      "     |      >>> print(T_test)\n",
      "     |                                   Test for Constraints\n",
      "     |      ==============================================================================\n",
      "     |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |      ------------------------------------------------------------------------------\n",
      "     |      c0         -1829.2026    455.391     -4.017      0.003   -2859.368    -799.037\n",
      "     |      ==============================================================================\n",
      "     |      >>> T_test.effect\n",
      "     |      -1829.2025687192481\n",
      "     |      >>> T_test.sd\n",
      "     |      455.39079425193762\n",
      "     |      >>> T_test.tvalue\n",
      "     |      -4.0167754636411717\n",
      "     |      >>> T_test.pvalue\n",
      "     |      0.0015163772380899498\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = sm.datasets.longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = 'GNPDEFL = GNP, UNEMP = 2, YEAR/1829 = 1'\n",
      "     |      >>> t_test = results.t_test(hypotheses)\n",
      "     |      >>> print(t_test)\n",
      "     |                                   Test for Constraints\n",
      "     |      ==============================================================================\n",
      "     |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |      ------------------------------------------------------------------------------\n",
      "     |      c0            15.0977     84.937      0.178      0.863    -177.042     207.238\n",
      "     |      c1            -2.0202      0.488     -8.231      0.000      -3.125      -0.915\n",
      "     |      c2             1.0001      0.249      0.000      1.000       0.437       1.563\n",
      "     |      ==============================================================================\n",
      "     |  \n",
      "     |  t_test_pairwise(self, term_name, method='hs', alpha=0.05, factor_labels=None)\n",
      "     |      Perform pairwise t_test with multiple testing corrected p-values.\n",
      "     |      \n",
      "     |      This uses the formula design_info encoding contrast matrix and should\n",
      "     |      work for all encodings of a main effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      term_name : str\n",
      "     |          The name of the term for which pairwise comparisons are computed.\n",
      "     |          Term names for categorical effects are created by patsy and\n",
      "     |          correspond to the main part of the exog names.\n",
      "     |      method : {str, list[str]}\n",
      "     |          The multiple testing p-value correction to apply. The default is\n",
      "     |          'hs'. See stats.multipletesting.\n",
      "     |      alpha : float\n",
      "     |          The significance level for multiple testing reject decision.\n",
      "     |      factor_labels : {list[str], None}\n",
      "     |          Labels for the factor levels used for pairwise labels. If not\n",
      "     |          provided, then the labels from the formula design_info are used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MultiCompResult\n",
      "     |          The results are stored as attributes, the main attributes are the\n",
      "     |          following two. Other attributes are added for debugging purposes\n",
      "     |          or as background information.\n",
      "     |      \n",
      "     |          - result_frame : pandas DataFrame with t_test results and multiple\n",
      "     |            testing corrected p-values.\n",
      "     |          - contrasts : matrix of constraints of the null hypothesis in the\n",
      "     |            t_test.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Status: experimental. Currently only checked for treatment coding with\n",
      "     |      and without specified reference level.\n",
      "     |      \n",
      "     |      Currently there are no multiple testing corrected confidence intervals\n",
      "     |      available.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res = ols(\"np.log(Days+1) ~ C(Weight) + C(Duration)\", data).fit()\n",
      "     |      >>> pw = res.t_test_pairwise(\"C(Weight)\")\n",
      "     |      >>> pw.result_frame\n",
      "     |               coef   std err         t         P>|t|  Conf. Int. Low\n",
      "     |      2-1  0.632315  0.230003  2.749157  8.028083e-03        0.171563\n",
      "     |      3-1  1.302555  0.230003  5.663201  5.331513e-07        0.841803\n",
      "     |      3-2  0.670240  0.230003  2.914044  5.119126e-03        0.209488\n",
      "     |           Conf. Int. Upp.  pvalue-hs reject-hs\n",
      "     |      2-1         1.093067   0.010212      True\n",
      "     |      3-1         1.763307   0.000002      True\n",
      "     |      3-2         1.130992   0.010212      True\n",
      "     |  \n",
      "     |  wald_test(self, r_matrix, cov_p=None, invcov=None, use_f=None, df_constraints=None, scalar=None)\n",
      "     |      Compute a Wald-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : {array_like, str, tuple}\n",
      "     |          One of:\n",
      "     |      \n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed that the\n",
      "     |            linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length p row vector.\n",
      "     |      \n",
      "     |      cov_p : array_like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      invcov : array_like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      use_f : bool\n",
      "     |          If True, then the F-distribution is used. If False, then the\n",
      "     |          asymptotic distribution, chisquare is used. If use_f is None, then\n",
      "     |          the F distribution is used if the model specifies that use_t is True.\n",
      "     |          The test statistic is proportionally adjusted for the distribution\n",
      "     |          by the number of constraints in the hypothesis.\n",
      "     |      df_constraints : int, optional\n",
      "     |          The number of constraints. If not provided the number of\n",
      "     |          constraints is determined from r_matrix.\n",
      "     |      scalar : bool, optional\n",
      "     |          Flag indicating whether the Wald test statistic should be returned\n",
      "     |          as a sclar float. The current behavior is to return an array.\n",
      "     |          This will switch to a scalar float after 0.14 is released. To\n",
      "     |          get the future behavior now, set scalar to True. To silence\n",
      "     |          the warning and retain the legacy behavior, set scalar to\n",
      "     |          False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ContrastResults\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      f_test : Perform an F tests on model parameters.\n",
      "     |      t_test : Perform a single hypothesis test.\n",
      "     |      statsmodels.stats.contrast.ContrastResults : Test results.\n",
      "     |      patsy.DesignInfo.linear_constraint : Specify a linear constraint.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |  \n",
      "     |  wald_test_terms(self, skip_single=False, extra_constraints=None, combine_terms=None, scalar=None)\n",
      "     |      Compute a sequence of Wald tests for terms over multiple columns.\n",
      "     |      \n",
      "     |      This computes joined Wald tests for the hypothesis that all\n",
      "     |      coefficients corresponding to a `term` are zero.\n",
      "     |      `Terms` are defined by the underlying formula or by string matching.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skip_single : bool\n",
      "     |          If true, then terms that consist only of a single column and,\n",
      "     |          therefore, refers only to a single parameter is skipped.\n",
      "     |          If false, then all terms are included.\n",
      "     |      extra_constraints : ndarray\n",
      "     |          Additional constraints to test. Note that this input has not been\n",
      "     |          tested.\n",
      "     |      combine_terms : {list[str], None}\n",
      "     |          Each string in this list is matched to the name of the terms or\n",
      "     |          the name of the exogenous variables. All columns whose name\n",
      "     |          includes that string are combined in one joint test.\n",
      "     |      scalar : bool, optional\n",
      "     |          Flag indicating whether the Wald test statistic should be returned\n",
      "     |          as a sclar float. The current behavior is to return an array.\n",
      "     |          This will switch to a scalar float after 0.14 is released. To\n",
      "     |          get the future behavior now, set scalar to True. To silence\n",
      "     |          the warning and retain the legacy behavior, set scalar to\n",
      "     |          False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      WaldTestResults\n",
      "     |          The result instance contains `table` which is a pandas DataFrame\n",
      "     |          with the test results: test statistic, degrees of freedom and\n",
      "     |          pvalues.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res_ols = ols(\"np.log(Days+1) ~ C(Duration, Sum)*C(Weight, Sum)\", data).fit()\n",
      "     |      >>> res_ols.wald_test_terms()\n",
      "     |      <class 'statsmodels.stats.contrast.WaldTestResults'>\n",
      "     |                                                F                P>F  df constraint  df denom\n",
      "     |      Intercept                        279.754525  2.37985521351e-22              1        51\n",
      "     |      C(Duration, Sum)                   5.367071    0.0245738436636              1        51\n",
      "     |      C(Weight, Sum)                    12.432445  3.99943118767e-05              2        51\n",
      "     |      C(Duration, Sum):C(Weight, Sum)    0.176002      0.83912310946              2        51\n",
      "     |      \n",
      "     |      >>> res_poi = Poisson.from_formula(\"Days ~ C(Weight) * C(Duration)\",                                            data).fit(cov_type='HC0')\n",
      "     |      >>> wt = res_poi.wald_test_terms(skip_single=False,                                          combine_terms=['Duration', 'Weight'])\n",
      "     |      >>> print(wt)\n",
      "     |                                  chi2             P>chi2  df constraint\n",
      "     |      Intercept              15.695625  7.43960374424e-05              1\n",
      "     |      C(Weight)              16.132616  0.000313940174705              2\n",
      "     |      C(Duration)             1.009147     0.315107378931              1\n",
      "     |      C(Weight):C(Duration)   0.216694     0.897315972824              2\n",
      "     |      Duration               11.187849     0.010752286833              3\n",
      "     |      Weight                 30.263368  4.32586407145e-06              4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |      Load a pickled results instance\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |         Loading pickled models is not secure against erroneous or\n",
      "     |         maliciously constructed data. Never unpickle data received from\n",
      "     |         an untrusted or unauthenticated source.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle, pathlib.Path}\n",
      "     |          A string filename or a file handle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          The unpickled results instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      "     |  \n",
      "     |  bse\n",
      "     |      The standard errors of the parameter estimates.\n",
      "     |  \n",
      "     |  tvalues\n",
      "     |      Return the t-statistic for a given parameter estimate.\n",
      "     |  \n",
      "     |  use_t\n",
      "     |      Flag indicating to use the Student's distribution in inference.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Results:\n",
      "     |  \n",
      "     |  initialize(self, model, params, **kwargs)\n",
      "     |      Initialize (possibly re-initialize) a Results instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      model : Model\n",
      "     |          The model instance.\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      **kwargs\n",
      "     |          Any additional keyword arguments required to initialize the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Results:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ARIMAResultsWrapper(statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper)\n",
      "     |  ARIMAResultsWrapper(results)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ARIMAResultsWrapper\n",
      "     |      statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResultsWrapper\n",
      "     |      statsmodels.base.wrapper.ResultsWrapper\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None)\n",
      "     |      conf_int(self, alpha=0.05, cols=None)\n",
      "     |      \n",
      "     |      Construct confidence interval for the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval. The default\n",
      "     |          `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array_like, optional\n",
      "     |          Specifies which confidence intervals to return.\n",
      "     |      \n",
      "     |      .. deprecated: 0.13\n",
      "     |      \n",
      "     |         cols is deprecated and will be removed after 0.14 is released.\n",
      "     |         cols only works when inputs are NumPy arrays and will fail\n",
      "     |         when using pandas Series or DataFrames as input. You can\n",
      "     |         subset the confidence intervals using slices.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution\n",
      "     |      if self.use_t is False. If self.use_t is True, then uses a Student's t\n",
      "     |      with self.df_resid_inference (or self.df_resid if df_resid_inference is\n",
      "     |      not defined) degrees of freedom.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      \n",
      "     |      Compute the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast of the\n",
      "     |      estimated parameters or all params multiplied by scale which will\n",
      "     |      usually be an estimate of sigma^2.  Scale is assumed to be a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array_like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column : array_like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      cov_p : ndarray, optional\n",
      "     |          The covariance of the parameters. If not provided, this value is\n",
      "     |          read from `self.normalized_cov_params` or\n",
      "     |          `self.cov_params_default`.\n",
      "     |      other : array_like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  forecast(self, steps=1, **kwargs)\n",
      "     |      forecast(self, steps=1, **kwargs)\n",
      "     |      \n",
      "     |      Out-of-sample forecasts\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      steps : int, str, or datetime, optional\n",
      "     |          If an integer, the number of steps to forecast from the end of the\n",
      "     |          sample. Can also be a date string to parse or a datetime type.\n",
      "     |          However, if the dates index does not have a fixed frequency, steps\n",
      "     |          must be an integer. Default\n",
      "     |      **kwargs\n",
      "     |          Additional arguments may required for forecasting beyond the end\n",
      "     |          of the sample. See `FilterResults.predict` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      forecast : array_like\n",
      "     |          Out-of-sample forecasts (Numpy array or Pandas Series or DataFrame,\n",
      "     |          depending on input and dimensions).\n",
      "     |          Dimensions are `(steps x k_endog)`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      predict\n",
      "     |          In-sample predictions and out-of-sample forecasts.\n",
      "     |      get_forecast\n",
      "     |          Out-of-sample forecasts and results including confidence intervals.\n",
      "     |      get_prediction\n",
      "     |          In-sample predictions / out-of-sample forecasts and results\n",
      "     |          including confidence intervals.\n",
      "     |  \n",
      "     |  impulse_responses(self, steps=1, impulse=0, orthogonalized=False, cumulative=False, **kwargs)\n",
      "     |      impulse_responses(self, steps=1, impulse=0, orthogonalized=False, cumulative=False, **kwargs)\n",
      "     |      \n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |  \n",
      "     |  predict(self, start=None, end=None, dynamic=False, **kwargs)\n",
      "     |      predict(self, start=None, end=None, dynamic=False, **kwargs)\n",
      "     |      \n",
      "     |      In-sample prediction and out-of-sample forecasting\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : {int, str,datetime}, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the zeroth observation.\n",
      "     |      end : {int, str,datetime}, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out of sample prediction. Default is the last observation in\n",
      "     |          the sample.\n",
      "     |      dynamic : {bool, int, str,datetime}, optional\n",
      "     |          Integer offset relative to `start` at which to begin dynamic\n",
      "     |          prediction. Can also be an absolute date string to parse or a\n",
      "     |          datetime type (these are not interpreted as offsets).\n",
      "     |          Prior to this observation, true endogenous values will be used for\n",
      "     |          prediction; starting with this observation and continuing through\n",
      "     |          the end of prediction, forecasted endogenous values will be used\n",
      "     |          instead.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments may be required for forecasting beyond the end\n",
      "     |          of the sample. See ``FilterResults.predict`` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : array_like\n",
      "     |          In-sample predictions / Out-of-sample forecasts. (Numpy array or\n",
      "     |          Pandas Series or DataFrame, depending on input and dimensions).\n",
      "     |          Dimensions are `(npredict x k_endog)`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      forecast\n",
      "     |          Out-of-sample forecasts.\n",
      "     |      get_forecast\n",
      "     |          Out-of-sample forecasts and results including confidence intervals.\n",
      "     |      get_prediction\n",
      "     |          In-sample predictions / out-of-sample forecasts and results\n",
      "     |          including confidence intervals.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, results)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __setstate__(self, dict_)\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      Save a pickle of this instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle}\n",
      "     |          Either a filename or a valid file handle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |      Load a pickled results instance\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |         Loading pickled models is not secure against erroneous or\n",
      "     |         maliciously constructed data. Never unpickle data received from\n",
      "     |         an untrusted or unauthenticated source.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle}\n",
      "     |          A string filename or a file handle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          The unpickled results instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    MEMORY_CONSERVE = 510\n",
      "\n",
      "FILE\n",
      "    c:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima\\model.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4242f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('https://raw.githubusercontent.com/slmsshk/DataSet/main/EURUSD_M1.csv',sep='\\t',parse_dates=True,index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
