{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e26993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T11:06:04.005613Z",
     "start_time": "2022-12-31T11:06:03.997630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 1 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ec2d3",
   "metadata": {},
   "source": [
    "# LeNet-5 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2304c46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T11:03:21.564879Z",
     "start_time": "2022-12-31T11:03:21.534987Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLeNet-5 is a small neural network by today’s standards. It has 61,706 parameters, compared\\nto millions of parameters in more modern networks, as you will see later in this\\nchapter.\\nA note when reading the papers discussed in this chapter\\nWhen you read the LeNet-5 paper, just know that it is harder to read than the others\\nwe will cover in this chapter. Most of the ideas that I mention in this section are in\\nsections 2 and 3 of the paper. The later sections of the paper talk about something\\ncalled the graph transformer network, which isn’t widely used today. So if you do try\\nto read the paper, I recommend focusing on section 2, which talks about the LeNet\\narchitecture and the learning details; then maybe take a quick look at section 3,\\nwhich includes a bunch of experiments and results that are pretty interesting.\\nI recommend starting with the AlexNet paper (discussed in section 5.3), followed by\\nthe VGGNet paper (section 5.4), and then the LeNet paper. It is a good classic to look\\nat once you go over the other ones.\\nImports the Keras\\nmodel and layers\\nInstantiates an empty\\nsequential model\\nFlattens the CNN output to\\nfeed it fully connected layers\\nPrints the model summary (figure 5.5)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "LeNet-5 is a small neural network by today’s standards. It has 61,706 parameters, compared\n",
    "to millions of parameters in more modern networks.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5106d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T11:03:55.555482Z",
     "start_time": "2022-12-31T11:03:47.423574Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Imports the Keras\n",
    "model and layers'''\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06aa2ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T11:06:17.769612Z",
     "start_time": "2022-12-31T11:06:17.623445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet-5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''Instantiates an empty\n",
    "sequential model'''\n",
    "model = Sequential(name='LeNet-5')\n",
    "# C1 Convolutional Layer\n",
    "model.add(Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'tanh',\n",
    "input_shape = (28,28,1), padding = 'same'))\n",
    "# S2 Pooling Layer\n",
    "model.add(AveragePooling2D(pool_size = 2, strides = 2, padding = 'valid'))\n",
    "# C3 Convolutional Layer\n",
    "model.add(Conv2D(filters = 16, kernel_size = 5, strides = 1,activation = 'tanh',\n",
    "padding = 'valid'))\n",
    "# S4 Pooling Layer\n",
    "model.add(AveragePooling2D(pool_size = 2, strides = 2, padding = 'valid'))\n",
    "# C5 Convolutional Layer\n",
    "model.add(Conv2D(filters = 120, kernel_size = 5, strides = 1,activation = 'tanh',\n",
    "padding = 'valid'))\n",
    "'''\n",
    "Flattens the CNN output to\n",
    "feed it fully connected layers'''\n",
    "model.add(Flatten())\n",
    "\n",
    "# FC6 Fully Connected Layer\n",
    "model.add(Dense(units = 84, activation = 'tanh'))\n",
    "# FC7 Output layer with softmax activation\n",
    "model.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "# Prints the model summary\n",
    "model.summary() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
