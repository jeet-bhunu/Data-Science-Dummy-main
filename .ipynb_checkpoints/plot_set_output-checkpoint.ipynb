{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introducing the `set_output` API\n",
    "\n",
    ".. currentmodule:: sklearn\n",
    "\n",
    "This example will demonstrate the `set_output` API to configure transformers to\n",
    "output pandas DataFrames. `set_output` can be configured per estimator by calling\n",
    "the `set_output` method or globally by setting `set_config(transform_output=\"pandas\")`.\n",
    "For details, see\n",
    "[SLEP018](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep018/proposal.html)_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the iris dataset as a DataFrame to demonstrate the `set_output` API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "60                 5.0               2.0                3.5               1.0\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "8                  4.4               2.9                1.4               0.2\n",
       "93                 5.0               2.3                3.3               1.0\n",
       "106                4.9               2.5                4.5               1.7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure an estimator such as :class:`preprocessing.StandardScaler` to return\n",
    "DataFrames, call `set_output`. This feature requires pandas to be installed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_output` can be called after `fit` to configure `transform` after the fact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "\n",
    "scaler2.fit(X_train)\n",
    "X_test_np = scaler2.transform(X_test)\n",
    "print(f\"Default output type: {type(X_test_np).__name__}\")\n",
    "\n",
    "scaler2.set_output(transform=\"pandas\")\n",
    "X_test_df = scaler2.transform(X_test)\n",
    "print(f\"Configured pandas output type: {type(X_test_df).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a :class:`pipeline.Pipeline`, `set_output` configures all steps to output\n",
    "DataFrames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(), SelectPercentile(percentile=75), LogisticRegression()\n",
    ")\n",
    "clf.set_output(transform=\"pandas\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transformer in the pipeline is configured to return DataFrames. This\n",
    "means that the final logistic regression step contains the feature names of the input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf[-1].feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the titanic dataset to demonstrate `set_output` with\n",
    ":class:`compose.ColumnTransformer` and heterogenous data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\n",
    "    \"titanic\", version=1, as_frame=True, return_X_y=True, parser=\"pandas\"\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `set_output` API can be configured globally by using :func:`set_config` and\n",
    "setting `transform_output` to `\"pandas\"`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "num_pipe = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "num_cols = [\"age\", \"fare\"]\n",
    "ct = ColumnTransformer(\n",
    "    (\n",
    "        (\"numerical\", num_pipe, num_cols),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(\n",
    "                sparse_output=False, drop=\"if_binary\", handle_unknown=\"ignore\"\n",
    "            ),\n",
    "            [\"embarked\", \"sex\", \"pclass\"],\n",
    "        ),\n",
    "    ),\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "clf = make_pipeline(ct, SelectPercentile(percentile=50), LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the global configuration, all transformers output DataFrames. This allows us to\n",
    "easily plot the logistic regression coefficients with the corresponding feature names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log_reg = clf[-1]\n",
    "coef = pd.Series(log_reg.coef_.ravel(), index=log_reg.feature_names_in_)\n",
    "_ = coef.sort_values().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resets `transform_output` to its default value to avoid impacting other\n",
    "examples when generating the scikit-learn documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(transform_output=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When configuring the output type with :func:`config_context` the\n",
    "configuration at the time when `transform` or `fit_transform` are\n",
    "called is what counts. Setting these only when you construct or fit\n",
    "the transformer has no effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import config_context\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with config_context(transform_output=\"pandas\"):\n",
    "    # the output of transform will be a Pandas DataFrame\n",
    "    X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outside of the context manager, the output will be a NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "X_test_scaled[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
